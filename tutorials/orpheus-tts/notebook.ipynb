{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb66c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from snac import SNAC\n",
    "import torch\n",
    "import requests\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "# --- Model and Tokenizer Setup ---\n",
    "tokenizer_name = \"canopylabs/3b-hi-ft-research_release\"\n",
    "\n",
    "snac_model_name = \"hubertsiuzdak/snac_24khz\"\n",
    "\n",
    "\n",
    "url = \"https://api.friendli.ai/dedicated/v1/completions\"\n",
    "friendli_token = os.environ.get(\"FRIENDLI_TOKEN\")\n",
    "friendli_model_id = os.environ.get(\"FRIENDLI_EID\") or \"YOUR_ENDPOINT_ID\" # Friendli AI Model ID e.g. \"fdo6dto2hkng\"\n",
    "\n",
    "# Load SNAC model (using CPU)\n",
    "snac_model = SNAC.from_pretrained(snac_model_name)\n",
    "snac_model = snac_model.to(\"cpu\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# --- Input Prompt Setup ---\n",
    "# Single prompt string\n",
    "prompt = \"हेलो आज आप कैसे हैं?\"\n",
    "chosen_voice = \"zoe\" # Voice to use (see GitHub for other voices)\n",
    "\n",
    "# Add voice tag to the prompt\n",
    "prompt = f\"{chosen_voice}: \" + prompt\n",
    "\n",
    "# --- Tokenization and Special Token Addition ---\n",
    "# Convert prompt to token IDs\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Define special tokens\n",
    "start_token = torch.tensor([[128259]], dtype=torch.int64) # Start of human\n",
    "end_tokens = torch.tensor([[128009, 128260]], dtype=torch.int64) # End of text, End of human\n",
    "\n",
    "# Add special tokens before and after input IDs (SOH SOT Text EOT EOH)\n",
    "modified_input_ids = torch.cat([start_token, input_ids, end_tokens], dim=1)\n",
    "\n",
    "# Check CUDA availability and set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_ids_for_api = modified_input_ids.to(device) # IDs for API transmission (to GPU if available)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Input token IDs for API: {input_ids_for_api}\")\n",
    "\n",
    "\n",
    "if not friendli_token:\n",
    "    raise ValueError(\"FRIENDLI_TOKEN environment variable must be set.\")\n",
    "\n",
    "# Configure API request payload\n",
    "payload = {\n",
    "    \"model\": friendli_model_id,\n",
    "    \"tokens\": input_ids_for_api.cpu().numpy().tolist()[0], # API expects a list of token IDs (move to CPU and convert)\n",
    "    \"max_tokens\": 1200,\n",
    "    \"temperature\": 0.6,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"eos_token\": [128258], # End of speech token\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + friendli_token,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Send API request\n",
    "print(\"Calling Friendli AI API...\")\n",
    "response = None # Initialize response to None for error handling scope\n",
    "try:\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    response.raise_for_status() # Raise exception for HTTP errors\n",
    "    response_data = response.json()\n",
    "    print(\"API call successful.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"API call failed: {e}\")\n",
    "    if response is not None:\n",
    "        print(f\"Response content: {response.text}\")\n",
    "    raise # Stop execution on error\n",
    "\n",
    "# Extract generated token IDs from API response\n",
    "response_ids = response_data['choices'][0]['tokens']\n",
    "generated_ids = torch.tensor([response_ids], dtype=torch.int64).to(device) # Convert results to tensor (to GPU if available)\n",
    "print(f\"Generated token IDs (Raw): {generated_ids}\")\n",
    "\n",
    "# --- Output Parsing and Audio Generation ---\n",
    "# Define tokens for parsing\n",
    "token_to_find = 128257  # Start of speech token\n",
    "token_to_remove = 128258 # End of speech token\n",
    "\n",
    "# Find Start of speech token (128257)\n",
    "token_indices = (generated_ids == token_to_find).nonzero(as_tuple=True)\n",
    "\n",
    "# Extract the part after the Start of speech token\n",
    "if len(token_indices[1]) > 0:\n",
    "    last_occurrence_idx = token_indices[1][-1].item()\n",
    "    cropped_tensor = generated_ids[:, last_occurrence_idx+1:]\n",
    "    print(f\"Token '{token_to_find}' found. Subsequent IDs: {cropped_tensor}\")\n",
    "else:\n",
    "    # If Start of speech token is not found, use the whole sequence (potential error)\n",
    "    cropped_tensor = generated_ids\n",
    "    print(f\"Warning: Token '{token_to_find}' (Start of speech) not found. Using all generated IDs.\")\n",
    "\n",
    "# Remove End of speech token (128258)\n",
    "mask = cropped_tensor != token_to_remove\n",
    "processed_tensor = cropped_tensor[mask].unsqueeze(0) # Make it a 1D tensor and restore to 2D\n",
    "\n",
    "print(f\"IDs after removing token '{token_to_remove}': {processed_tensor}\")\n",
    "\n",
    "# Prepare for conversion to audio codes (process in units of 7)\n",
    "code_list = []\n",
    "if processed_tensor.numel() > 0: # Check if there are tokens to process\n",
    "    row = processed_tensor[0] # Select the first (only) row\n",
    "    row_length = row.size(0)\n",
    "    # Adjust length to be a multiple of 7 (remove last incomplete set)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    if new_length < row_length:\n",
    "         print(f\"Warning: The last {row_length - new_length} tokens are ignored as they form an incomplete set of 7.\")\n",
    "\n",
    "    if new_length > 0:\n",
    "        trimmed_row = row[:new_length]\n",
    "        # Adjust token ID offset (subtract 128266)\n",
    "        code_list = [t.item() - 128266 for t in trimmed_row]\n",
    "        print(f\"Audio codes (length: {len(code_list)}): {code_list[:21]}...\") # Print only the beginning part\n",
    "    else:\n",
    "        print(\"No valid tokens to convert to audio codes.\")\n",
    "else:\n",
    "    print(\"No generated tokens to process.\")\n",
    "\n",
    "# Audio code redistribution function\n",
    "def redistribute_codes(single_code_list):\n",
    "  if not single_code_list:\n",
    "      return torch.tensor([]) # Return empty tensor for empty list\n",
    "\n",
    "  layer_1 = []\n",
    "  layer_2 = []\n",
    "  layer_3 = []\n",
    "  num_frames = len(single_code_list) // 7\n",
    "\n",
    "  for i in range(num_frames):\n",
    "    try:\n",
    "        # Apply offset for each layer to separate codes\n",
    "        layer_1.append(single_code_list[7*i])\n",
    "        layer_2.append(single_code_list[7*i+1] - 4096)\n",
    "        layer_3.append(single_code_list[7*i+2] - (2*4096))\n",
    "        layer_3.append(single_code_list[7*i+3] - (3*4096))\n",
    "        layer_2.append(single_code_list[7*i+4] - (4*4096))\n",
    "        layer_3.append(single_code_list[7*i+5] - (5*4096))\n",
    "        layer_3.append(single_code_list[7*i+6] - (6*4096))\n",
    "    except IndexError as e:\n",
    "        # This part handles potential errors if the list length isn't a perfect multiple of 7\n",
    "        # after trimming, though the trimming logic should prevent this.\n",
    "        print(f\"Warning: Error accessing index during code redistribution: {e}. The last frame might be incomplete.\")\n",
    "        break # Stop if frame is incomplete\n",
    "\n",
    "  # Convert to tensor (add batch dimension)\n",
    "  codes = [torch.tensor(layer_1).unsqueeze(0),\n",
    "           torch.tensor(layer_2).unsqueeze(0),\n",
    "           torch.tensor(layer_3).unsqueeze(0)]\n",
    "\n",
    "  # Decode audio with SNAC model\n",
    "  print(f\"SNAC Decoding: Layer 1 ({len(layer_1)}), Layer 2 ({len(layer_2)}), Layer 3 ({len(layer_3)}) codes\")\n",
    "  if not layer_1 or not layer_2 or not layer_3:\n",
    "      print(\"Warning: Insufficient codes for decoding.\")\n",
    "      return torch.tensor([])\n",
    "\n",
    "  audio_hat = snac_model.decode(codes)\n",
    "  return audio_hat\n",
    "\n",
    "# Generate audio\n",
    "samples = torch.tensor([]) # Default empty tensor\n",
    "if code_list: # Execute only if code_list is not empty\n",
    "    samples = redistribute_codes(code_list)\n",
    "    print(\"Audio generation complete.\")\n",
    "else:\n",
    "    print(\"Skipping audio generation as there are no audio codes.\")\n",
    "\n",
    "# --- Audio Output ---\n",
    "if samples.numel() > 0: # Check if generated audio samples exist\n",
    "    print(\"\\n--- Generated Audio ---\")\n",
    "    print(f\"Input prompt: {prompt}\")\n",
    "    # Display audio (works in Jupyter/Colab environments)\n",
    "    display(Audio(samples.detach().squeeze().cpu().numpy(), rate=24000))\n",
    "else:\n",
    "    print(\"\\nNo generated audio.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
